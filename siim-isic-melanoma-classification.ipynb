{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import shutil\n",
    "import datetime\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import pydicom\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as KL\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "import efficientnet.tfkeras as efn # https://github.com/qubvel/efficientnet\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Check GPUs:\",\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            # Prevent TensorFlow from allocating all memory of all GPUs:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)\n",
    "#print('Compute dtype: %s' % policy.compute_dtype)\n",
    "#print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JPEG_TRAIN = 'data/siim-isic-melanoma-classification/jpeg/train'\n",
    "JPEG_VAL = 'data/siim-isic-melanoma-classification/jpeg/val'\n",
    "JPEG_TEST = 'data/siim-isic-melanoma-classification/jpeg/test'\n",
    "DCM_TRAIN = 'data/siim-isic-melanoma-classification/train'\n",
    "DCM_VAL = 'data/siim-isic-melanoma-classification/val'\n",
    "DCM_TEST = 'data/siim-isic-melanoma-classification/test'\n",
    "CSV_TRAIN = 'data/siim-isic-melanoma-classification/train.csv'\n",
    "CSV_TEST = 'data/siim-isic-melanoma-classification/test.csv'\n",
    "SUBMITS_DIR = 'submits/siim-isic-melanoma-classification'\n",
    "\n",
    "CACHE_FILE = 'cache/siim-isic-melanoma-classification/cache'\n",
    "\n",
    "N_TEST = 10982\n",
    "\n",
    "WIDTH_PRE, HEIGHT_PRE = 768, 768\n",
    "\n",
    "WIDTH_0, HEIGHT_0 = 224, 224\n",
    "WIDTH_4, HEIGHT_4 = 380, 380\n",
    "#WIDTH_5, HEIGHT_5 = 456, 456\n",
    "#WIDTH_7, HEIGHT_7 = 600, 600\n",
    "#WIDTH_7, HEIGHT_7 = 768, 768\n",
    "#WIDTH, HEIGHT = 448, 448\n",
    "#WIDTH, HEIGHT = 896, 896\n",
    "#WIDTH, HEIGHT = 768, 768\n",
    "#WIDTH, HEIGHT = 1024, 1024\n",
    "#WIDTH, HEIGHT = 1120, 1120\n",
    "\n",
    "WIDTH, HEIGHT = WIDTH_0, HEIGHT_0\n",
    "WIDTH, HEIGHT = WIDTH_4, HEIGHT_4\n",
    "\n",
    "\n",
    "# AUGMENTATIONS:\n",
    "FLIP_ROT = True\n",
    "BR_SAT_CON = False\n",
    "CROP = False\n",
    "\n",
    "TEST_AUGMENT_N = 16\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc')\n",
    "]\n",
    "\n",
    "BODY_PARTS_ONE_HOT = {'HEAD/NECK':       [1,0,0,0,0,0,0], \n",
    "                      'LOWER EXTREMITY': [0,1,0,0,0,0,0],\n",
    "                      'ORAL/GENITAL':    [0,0,1,0,0,0,0],\n",
    "                      'PALMS/SOLES':     [0,0,0,1,0,0,0],\n",
    "                      'TORSO':           [0,0,0,0,1,0,0],\n",
    "                      'UPPER EXTREMITY': [0,0,0,0,0,1,0], \n",
    "                      'SKIN':            [0,0,0,0,0,0,1]\n",
    "                     }\n",
    "PATIENT_DATA_LEN = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(CSV_TRAIN)\n",
    "meta_test = pd.read_csv(CSV_TEST)\n",
    "meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(meta_df, train_path, val_path, val_percent = 0.25, seed = 18, file_ext = 'jpg'):\n",
    "    n = len(meta_df)\n",
    "    n_val = int(n * val_percent)\n",
    "    n_train = n - n_val\n",
    "    train_val = ['train'] * n_train + ['val'] * n_val\n",
    "    random.seed(seed)\n",
    "    random.shuffle(train_val)\n",
    "    meta_df['train_val'] = train_val\n",
    "    \n",
    "    p = pathlib.Path(train_path)\n",
    "    l = list(p.glob(str('**/*.' + file_ext)))\n",
    "    if len(l) != n:\n",
    "        print('Is train/val split already done?')\n",
    "        return meta_df\n",
    "    \n",
    "    i = 0\n",
    "    for source in l:\n",
    "        #print(source)\n",
    "        if meta_df.loc[meta_df['image_name'] == source.stem, 'train_val'].values[0] == 'val':\n",
    "            #print('val', source.stem)\n",
    "            dest = pathlib.Path(val_path, source.name)\n",
    "            #print(dest)\n",
    "            shutil.move(source, dest)\n",
    "            i += 1\n",
    "    \n",
    "    if i == n_val:\n",
    "        print(n_val, 'validation images moved to validation directory')\n",
    "    else:\n",
    "        print('There is a discrepancy in number of validation images moved')\n",
    "        print('Images supposed to be moved:', n_val)\n",
    "        print('Images moved:', i)\n",
    "    \n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta = split_train_val(meta, JPEG_TRAIN, JPEG_VAL, file_ext = 'jpg')\n",
    "meta = split_train_val(meta, DCM_TRAIN, DCM_VAL, file_ext = 'dcm')\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_target_subfolders(meta_df, data_path, target_list, file_ext = 'jpg'):\n",
    "    \n",
    "    p = pathlib.Path(data_path)\n",
    "    for target in target_list:\n",
    "        p_target = p.joinpath(str(target))\n",
    "        p_target.mkdir(exist_ok = True)\n",
    "    \n",
    "    l = list(p.glob(str('**/*.' + file_ext)))\n",
    "    \n",
    "    for p_image in l:\n",
    "        image_name = p_image.stem\n",
    "        #print(image_name)\n",
    "        target = meta_df.loc[meta_df['image_name'] == image_name, 'target'].values[0]\n",
    "        #print(target)\n",
    "        p_target = p.joinpath(str(target)).joinpath(p_image.name)\n",
    "        shutil.move(p_image, p_target)\n",
    "        #print(p_target)\n",
    "        #break\n",
    "    print('Images moved to target subfolders')\n",
    "        \n",
    "#move_to_target_subfolders(meta, JPEG_TRAIN, [0, 1], file_ext = 'jpg')\n",
    "#move_to_target_subfolders(meta, JPEG_VAL, [0, 1], file_ext = 'jpg')\n",
    "#move_to_target_subfolders(meta, DCM_TRAIN, [0, 1], file_ext = 'dcm')\n",
    "#move_to_target_subfolders(meta, DCM_VAL, [0, 1], file_ext = 'dcm')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def one_hot(meta, train_test = 'train'):\n",
    "    anatom = pd.get_dummies(meta['anatom_site_general_challenge'], prefix = 'anatom')\n",
    "    meta[anatom.columns] = anatom\n",
    "    sex = pd.get_dummies(meta['sex'], prefix = 'sex')\n",
    "    meta[sex.columns] = sex\n",
    "    meta.drop(['sex', \n",
    "               'anatom_site_general_challenge', \n",
    "               'patient_id'], axis = 1, inplace = True)\n",
    "    if train_test == 'train':\n",
    "        meta.drop(['diagnosis', 'benign_malignant', 'train_val', 'target'], axis = 1, inplace = True)\n",
    "    meta['age_approx'] = meta['age_approx']/100\n",
    "\n",
    "one_hot(meta, train_test = 'train')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "meta[meta['anatom_upper extremity'] == 1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "one_hot(meta_test, train_test = 'test')\n",
    "meta_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lookup_meta_train = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(meta['image_name']),\n",
    "        values=tf.constant(np.array(meta.iloc[:,1:], dtype = 'float32')), value_dtype = tf.float32\n",
    "    ),\n",
    "    default_value=tf.constant(np.array([[-1.0]*9],), dtype = tf.float32),\n",
    "    name=\"target_lookup\"\n",
    ")\n",
    "\n",
    "# test lookup\n",
    "input_tensor = tf.constant(meta['image_name'][91])\n",
    "out = lookup_meta_train.lookup(input_tensor)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_attributes(image_name):\n",
    "    return np.array(meta[meta['image_name'] == image_name].iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pydicom.dcmread(str(DCM_TRAIN + '/0/ISIC_9999320.dcm'))\n",
    "age = int(ds.PatientAge[:-1]) / 100\n",
    "sex = ds.PatientSex\n",
    "if sex == 'M':\n",
    "    sex = 1\n",
    "else:\n",
    "    sex = 0\n",
    "body_part = np.array(BODY_PARTS_ONE_HOT[ds.BodyPartExamined])\n",
    "patient_info = np.concatenate([np.array([age, sex]), body_part])\n",
    "patient_info = tf.convert_to_tensor(patient_info, dtype = tf.float32)\n",
    "patient_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def augment(img_patient_data, label):\n",
    "    img, patient_data = img_patient_data\n",
    "    #if CROP:\n",
    "    #    crop_factor = tf.random.uniform(shape = (), minval = 1, maxval = 1.5)\n",
    "    #    #tf.print(crop_factor)\n",
    "    #    img = preprocess_images(img, int(HEIGHT*crop_factor), int(WIDTH*crop_factor))\n",
    "    #    img = tf.image.random_crop(img, [HEIGHT, WIDTH, 3])\n",
    "        \n",
    "    if FLIP_ROT:\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "        k = tf.random.uniform(shape = (), minval=0, maxval=4, dtype=tf.int32)\n",
    "        img = tf.image.rot90(img, k)\n",
    "        \n",
    "    if BR_SAT_CON:\n",
    "        img = tf.image.random_brightness(img, max_delta=63. / 255.)\n",
    "        img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
    "        img = tf.image.random_contrast(img, lower=0.2, upper=1.8)\n",
    "    return (img, patient_data), label\n",
    "\n",
    "def decode_dcm_img(img_path):\n",
    "    img_path = str(img_path.numpy(), 'utf-8')\n",
    "    ds = pydicom.dcmread(img_path)\n",
    "    img = ds.pixel_array\n",
    "    img = pydicom.pixel_data_handlers.util.convert_color_space(img, 'YBR_FULL_422', 'RGB')\n",
    "    img = tf.convert_to_tensor(img, dtype = tf.uint8)\n",
    "    return img\n",
    "\n",
    "def resize(img_patient_data, label):\n",
    "    img, patient_data = img_patient_data\n",
    "    #img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [HEIGHT, WIDTH])\n",
    "    return (img, patient_data), label\n",
    "\n",
    "def resize_with_crop(img_patient_data, label):\n",
    "    img, patient_data = img_patient_data\n",
    "    #img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, HEIGHT, WIDTH)\n",
    "    return (img, patient_data), label\n",
    "\n",
    "def resize_with_pad(img_patient_data, label):\n",
    "    img, patient_data = img_patient_data\n",
    "    #img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize_with_pad(img, HEIGHT, WIDTH)\n",
    "    return (img, patient_data), label\n",
    "    \n",
    "def decode_dcm_patient_data(img_path):\n",
    "    img_path = str(img_path.numpy(), 'utf-8')\n",
    "    ds = pydicom.dcmread(img_path)\n",
    "    \n",
    "    # Patient meta\n",
    "    age = int(ds.PatientAge[:-1]) / 100\n",
    "    sex = ds.PatientSex\n",
    "    if sex == 'M':\n",
    "        sex = 1\n",
    "    else:\n",
    "        sex = 0\n",
    "    body_part = np.array(BODY_PARTS_ONE_HOT[ds.BodyPartExamined])\n",
    "    patient_data = np.concatenate([np.array([age, sex]), body_part])\n",
    "    patient_data = tf.convert_to_tensor(patient_data, dtype = tf.float32)\n",
    "    \n",
    "    return patient_data\n",
    "    \n",
    "def process_path(img_path):\n",
    "    #image_name = tf.strings.split(tf.strings.split(img_path, os.sep)[-1], '.')[0]\n",
    "    #ext = tf.strings.split(tf.strings.split(img_path, os.sep)[-1], '.')[1]\n",
    "    #tf.print(image_name)\n",
    "    train_val_test = tf.strings.split(img_path, os.sep)[2]\n",
    "    #tf.print(train_val_test)\n",
    "\n",
    "    if train_val_test != tf.constant('test', dtype = tf.string):\n",
    "        label = tf.strings.split(img_path, os.sep)[-2]\n",
    "        label = tf.strings.to_number(label, tf.int32) \n",
    "    else:\n",
    "        label = -1\n",
    "    \n",
    "    img = tf.py_function(func = decode_dcm_img, inp = [img_path], Tout = tf.uint8)\n",
    "    img.set_shape([None, None, 3])\n",
    "\n",
    "    patient_data = tf.py_function(func = decode_dcm_patient_data, inp = [img_path], Tout = tf.float32)\n",
    "    patient_data.set_shape([PATIENT_DATA_LEN])\n",
    "    #tf.print('patient_data', patient_data)\n",
    "    \n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [HEIGHT_PRE, WIDTH_PRE])\n",
    "    #img = tf.image.resize_with_pad(img, HEIGHT_PRE, WIDTH_PRE)\n",
    "    \n",
    "    #tf.print(img.shape, patient_data.shape, label.shape)\n",
    "    return (img, patient_data), label\n",
    "\n",
    "def dataset_from_image_files(img_path, shuffle_buffer_size, cache = False, ext = 'dcm', test_augment = False):\n",
    "    train_val_test = img_path.split('/')[2]\n",
    "    if img_path.split('/')[-1] != train_val_test:\n",
    "        target = img_path.split('/')[-1]\n",
    "    else:\n",
    "        target = None\n",
    "    \n",
    "    if train_val_test == 'test':\n",
    "        ds = tf.data.Dataset.list_files(str(img_path + '*.' + ext), shuffle = False)\n",
    "    else:\n",
    "        ds = tf.data.Dataset.list_files(str(img_path + '*.' + ext), shuffle = True)\n",
    "    ds = ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if isinstance(cache, str):\n",
    "        ds = ds.cache(str(cache + '-pre-' + str(HEIGHT_PRE) + 'x' + str(WIDTH_PRE)))\n",
    "    \n",
    "    ds = ds.map(resize, num_parallel_calls=AUTOTUNE)\n",
    "    #ds = ds.map(resize_with_crop, num_parallel_calls=AUTOTUNE)\n",
    "    #ds = ds.map(resize_with_pad, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if isinstance(cache, str):\n",
    "        ds = ds.cache(str(cache + '-' + str(HEIGHT) + 'x' + str(WIDTH)))\n",
    "        \n",
    "    if train_val_test != 'test':\n",
    "        ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "        ds = ds.repeat()\n",
    "\n",
    "    if test_augment:\n",
    "        ds = ds.repeat(TEST_AUGMENT_N)\n",
    "        ds = ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "        \n",
    "    if target == '1' and train_val_test == 'train':\n",
    "        tf.print('augmenting', img_path)\n",
    "        ds = ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "        \n",
    "    if target == None:\n",
    "        ds = ds.batch(BATCH_SIZE)\n",
    "    \n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dataset_combine(img_path, cache, shuffle_buffer_size = 1000):\n",
    "    ds_0 = dataset_from_image_files(str(img_path + '/0'),\n",
    "                                    shuffle_buffer_size = shuffle_buffer_size, \n",
    "                                    cache = str(cache + '-0'), ext = 'dcm')\n",
    "    ds_1 = dataset_from_image_files(str(img_path + '/1'), \n",
    "                                    shuffle_buffer_size = shuffle_buffer_size, \n",
    "                                    cache = str(cache + '-1'), ext = 'dcm')\n",
    "\n",
    "    w = 0.8\n",
    "    ds = tf.data.experimental.sample_from_datasets([ds_0, ds_1], weights=[w, 1-w])\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "ds_train = dataset_combine(DCM_TRAIN, cache = str(CACHE_FILE + '-train'), \n",
    "                           shuffle_buffer_size = 1000)\n",
    "\n",
    "ds_val = dataset_from_image_files(DCM_VAL, shuffle_buffer_size = 1000, \n",
    "                                  cache = str(CACHE_FILE + '-val'), ext = 'dcm')\n",
    "\n",
    "ds_test = dataset_from_image_files(DCM_TEST, shuffle_buffer_size = 100, \n",
    "                                  cache = str(CACHE_FILE + '-test'), ext = 'dcm')\n",
    "\n",
    "ds_test_augment = dataset_from_image_files(DCM_TEST, shuffle_buffer_size = 100, \n",
    "                                           cache = str(CACHE_FILE + '-test'), ext = 'dcm', \n",
    "                                           test_augment = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image, patient_data, label):\n",
    "    for i in range(BATCH_SIZE):\n",
    "        plt.figure()\n",
    "        plt.imshow(image[i,:,:,:])\n",
    "        plt.title(str(i) + ' - ' + str(label.numpy()[i]) + str(patient_data.numpy()[i]))\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (image, patient_data), label in ds_test_augment.take(1):\n",
    "    show(image, patient_data, label)\n",
    "    print(label.shape)\n",
    "    print(image.shape)\n",
    "    print(image.dtype)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i = 0\n",
    "for (image, patient_data), label in ds_train:\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    if i == int(60000/BATCH_SIZE):\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i = 0\n",
    "for (image, patient_data), label in ds_test:\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i = 0\n",
    "for (image, patient_data), label in ds_val:\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    if i == int(15000/BATCH_SIZE):\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def build_resnet50():\n",
    "    base_model = tf.keras.applications.ResNet50(include_top=True, weights=None, \n",
    "                                            input_tensor=None, input_shape=(HEIGHT, WIDTH, 3),\n",
    "                                            pooling=None)\n",
    "    #base_model.summary()\n",
    "    new_output = KL.Dense(1, activation = 'sigmoid', dtype = 'float32')(base_model.layers[-2].output)\n",
    "    model = Model(base_model.input, new_output)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=METRICS)\n",
    "    model.summary()\n",
    "    return model\n",
    "#model = build_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_efficientnet_bX(level = 0, lr = 0.001, compile_model = True, last_layer = True, \n",
    "                          height = HEIGHT, width = WIDTH):\n",
    "    if level == 0:\n",
    "        base_model = efn.EfficientNetB0(include_top=True, weights='noisy-student',\n",
    "                                   input_shape=(height, width, 3))\n",
    "    elif level == 1:\n",
    "        base_model = efn.EfficientNetB1(include_top=True, weights='noisy-student',\n",
    "                                   input_shape=(height, width, 3))\n",
    "    elif level == 2:\n",
    "        base_model = efn.EfficientNetB2(include_top=True, weights='noisy-student',\n",
    "                                   input_shape=(height, width, 3))\n",
    "    elif level == 3:\n",
    "        base_model = efn.EfficientNetB3(include_top=True, weights='noisy-student',\n",
    "                                   input_shape=(height, width, 3))\n",
    "    elif level == 4:\n",
    "        base_model = efn.EfficientNetB4(include_top=True, weights='noisy-student',\n",
    "                                   input_shape=(height, width, 3))\n",
    "    elif level == 5:\n",
    "        base_model = efn.EfficientNetB5(include_top=True, weights='noisy-student',\n",
    "                                   input_shape=(height, width, 3))\n",
    "    elif level == 6:\n",
    "        base_model = efn.EfficientNetB6(include_top=True, weights='noisy-student',\n",
    "                                   input_shape=(height, width, 3))\n",
    "    elif level == 7:\n",
    "        base_model = efn.EfficientNetB7(include_top=True, weights='noisy-student',\n",
    "                                   input_shape=(height, width, 3))\n",
    "    \n",
    "    patient_data_input = KL.Input(shape = (PATIENT_DATA_LEN,), name = 'patient_data_input')\n",
    "    new_effnet_output = KL.Dense(7, activation = 'relu')(base_model.layers[-2].output)\n",
    "    x = KL.concatenate([new_effnet_output, patient_data_input])\n",
    "    x = KL.Dropout(0.5)(x)\n",
    "    x = KL.Dense(8, activation = 'relu')(x)\n",
    "    x = KL.Dropout(0.5)(x)\n",
    "    x = KL.Dense(16, activation = 'relu')(x)\n",
    "    x = KL.Dropout(0.5)(x)\n",
    "    x = KL.Dense(8, activation = 'relu')(x)\n",
    "    x = KL.Dropout(0.5)(x)\n",
    "    if last_layer:\n",
    "        x = KL.Dense(1, activation = 'sigmoid')(x)\n",
    "        \n",
    "    model = Model((base_model.input, patient_data_input), x)\n",
    "    \n",
    "    if compile_model:\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=opt,\n",
    "                      metrics=METRICS)\n",
    "    model.summary()\n",
    "    return model\n",
    "model_0 = build_efficientnet_bX(level = 0, compile_model = True, last_layer = True, \n",
    "                                lr = 0.0005, height = HEIGHT_0, width = WIDTH_0)\n",
    "model_4 = build_efficientnet_bX(level = 4, compile_model = True, last_layer = True, \n",
    "                                lr = 0.00001, height = HEIGHT_4, width = WIDTH_4)\n",
    "#model_4_crop = build_efficientnet_bX(level = 4, compile_model = True, last_layer = True, \n",
    "#                                     lr = 0.001, height = HEIGHT_4, width = WIDTH_4)\n",
    "#model_5 = build_efficientnet_bX(level = 5, compile_model = True, last_layer = True, \n",
    "#                                lr = 0.001, height = HEIGHT_5, width = WIDTH_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tb_callback(model_name):\n",
    "    log_dir = pathlib.Path('logs/siim-isic-melanoma-classification/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = str('models/siim-isic-melanoma-classification/'+model_name+'-{epoch:02d}-{val_auc:.4f}.h5'), \n",
    "        monitor = \"val_auc\",\n",
    "        mode='max',\n",
    "        save_best_only = False,\n",
    "        save_weights_only = True,\n",
    "    )\n",
    "    return [tensorboard_callback, checkpoint_callback]\n",
    "callbacks_0 = tb_callback(str('effnet-b0-' + str(WIDTH_0)))\n",
    "callbacks_4 = tb_callback(str('effnet-b4-' + str(WIDTH_4)))\n",
    "callbacks_4_crop = tb_callback(str('effnet-b4-crop' + str(WIDTH_4)))\n",
    "#callbacks_5 = tb_callback(str('effnet-b5-' + str(WIDTH_5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.load_weights('models/siim-isic-melanoma-classification/effnet-b0-224-11-0.8551.h5')\n",
    "model_4.load_weights('models/siim-isic-melanoma-classification/effnet-b4-380-01-0.8948.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "history = model_0.fit(ds_train, \n",
    "                      validation_data = ds_val,\n",
    "                      epochs = 20, \n",
    "                      steps_per_epoch = 1500, \n",
    "                      validation_steps = 1500, \n",
    "                      callbacks = callbacks_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_4.fit(ds_train, \n",
    "                      validation_data = ds_val,\n",
    "                      epochs = 2, \n",
    "                      steps_per_epoch = 1500, \n",
    "                      validation_steps = 1500, \n",
    "                      callbacks = callbacks_4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history = model_4_crop.fit(ds_train, \n",
    "                           validation_data = ds_val,\n",
    "                           epochs = 30, \n",
    "                           steps_per_epoch = 1500, \n",
    "                           validation_steps = 1500, \n",
    "                           callbacks = callbacks_4_crop)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history = model_5.fit(ds_train, \n",
    "                      validation_data = ds_val,\n",
    "                      epochs = 30, \n",
    "                      steps_per_epoch = 1500, \n",
    "                      validation_steps = 1500, \n",
    "                      callbacks = callbacks_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(ds_val, steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('models/siim-isic-melanoma-classification/2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img_path, dataset, csv_filename = False, take = False, ext = 'jpg', augment = False):\n",
    "    p = pathlib.Path(img_path)\n",
    "    l = list(p.glob(str('**/*.' + ext)))\n",
    "    image_names = [p.stem for p in l]\n",
    "    \n",
    "    if not take:\n",
    "        print(take)\n",
    "        preds = model.predict(dataset, verbose = 1)\n",
    "        preds = np.ndarray.flatten(preds)\n",
    "\n",
    "        print(preds.shape)\n",
    "        if augment:\n",
    "            preds = np.reshape(preds, (N_TEST, -1))\n",
    "            print(preds.shape)\n",
    "            preds = np.mean(preds, axis = 1)\n",
    "        print(preds.shape)\n",
    "        df = pd.DataFrame({'image_name': image_names, \n",
    "                           'target': preds})\n",
    "        \n",
    "    else:\n",
    "        print(take)\n",
    "        preds = model.predict(dataset.take(take), verbose = 1)\n",
    "        print(preds.shape)\n",
    "        preds = np.ndarray.flatten(preds)\n",
    "        print(preds.shape)\n",
    "        if augment:\n",
    "            preds = np.reshape(preds, (N_TEST, -1))\n",
    "            print(preds.shape)\n",
    "            preds = np.mean(preds, axis = 1)\n",
    "        print(preds.shape)\n",
    "        df = pd.DataFrame({'image_name': image_names[:take*BATCH_SIZE], \n",
    "                           'target': preds})\n",
    "    \n",
    "    if isinstance(csv_filename, str):\n",
    "        df.to_csv(pathlib.Path(SUBMITS_DIR, csv_filename), index = False)\n",
    "    return df\n",
    "\n",
    "#predicts = predict(model_4, DCM_TEST, ds_test, 'submit-22.csv', take = False, ext = 'dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_0 = predict(model_0, DCM_TEST, ds_test_augment, csv_filename = False, \n",
    "                  take = False, ext = 'dcm', augment = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds_4 = predict(model_4, DCM_TEST, ds_test, csv_filename = 'submit-30.csv', take = False, ext = 'dcm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
